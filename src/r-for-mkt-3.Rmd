---
title: "Relationships Between Continuous Variables"
author: "Bruno Flores"
date: "26 de junho de 2015"
output: 
  html_document: 
    self_contained: no
---

# Retailer Data

## Simulating Customer Data

This data is typical of what one might sample from a company's customer 
relationship management (CRM) system.

```{r}
set.seed(21821)
ncust <- 1000
cust.df <- data.frame(cust.id = as.factor(c(1:ncust)))
```

Credit scores are also simulated with a normal distribution, with older 
customers having higher credit scores on average.

Distance to store we assume follows the *exponential of the normal distribution*, 
that gives distances that are all positive, with many distances that are 
relatively close to the nearest store and fewer that are far from the store.

```{r}
cust.df$age <- rnorm(n = ncust, mean = 35, sd = 5)
cust.df$credit.score <- rnorm(n = ncust, mean = 3*cust.df$age+620, sd = 50)
cust.df$email <- factor(sample(c("yes", "no"), size = ncust, 
                               replace = TRUE, prob = c(0.8, 0.2)))
cust.df$distance.to.store <- exp(rnorm(n = ncust, mean = 2, sd = 1.2))
summary(cust.df)
```

## Simulating Online and In-Store Sales Data

Number of visits simulated with *negative binomial*, a discrete distribution 
often used to model counts of events over time.

Generates positive values and has a long right-hand tail, meaning that in 
our data most customers make relatively few visits and a few customers 
make many visits:

```{r}
cust.df$online.visits <- rnbinom(ncust, 
                                 size = 0.3, # Degree of dispertion (variation)
                                 mu = 15 + ifelse(cust.df$email == "yes", 15, 0)
                                 - 0.7 * (cust.df$age - median(cust.df$age)))
```

We add or subtract visits from the target mean based on the customer's 
age relative to the sample median: customers who are yunger are simulated 
to make more online visits.

For each online visit that a user makes, we assume there is a 30% chance 
of placing an order:

```{r}
cust.df$online.trans <- rbinom(ncust, size = cust.df$online.visits, prob = 0.3)
```

The random value for amount spent per transaction is multiplied by the 
variable for number of transactions to get the total amount spent:

```{r}
cust.df$online.spend <- exp(rnorm(ncust, mean = 3, sd = 0.1)) * 
        cust.df$online.trans
```

For In-Store sales we assume that transactions follow a *negative binomial* 
distribution, with lower average numbers of visits for customers who live 
farther away:

```{r}
cust.df$store.trans <- rnbinom(ncust, size = 5,
                               mu = 3 / sqrt(cust.df$distance.to.store))
cust.df$store.spend <- exp(rnorm(ncust, mean = 3.5, sd = 0.4)) * 
        cust.df$store.trans
```

## Simulating Satisfction Survey Responses

To simulate survey responses, we assume that each customer has an unobserved 
overall satisfaction with the brand:

```{r}
sat.overall <- rnorm(ncust, mean = 3.1, sd = 0.7)
summary(sat.overall)
```

We assume that customer' responses to the survey items are based on unobserved 
levels of satisfaction *overall* plus the specific levels of satisfaction with 
the service and product selection:

```{r}
sat.service <- floor(sat.overall + rnorm(ncust, mean = 0.5, sd = 0.4))
sat.selection <- floor(sat.overall + rnorm(ncust, mean = 0.2, sd = 0.6))
summary(cbind(sat.service, sat.selection))
```

Enforcing the *floor* and *ceiling* effects:

```{r}
sat.service[sat.service > 5] <- 5
sat.service[sat.service < 1] <- 1
sat.selection[sat.selection > 5] <- 5
sat.selection[sat.selection < 1] <- 1
summary(cbind(sat.service, sat.selection))
```

## Simulating Non-Response Data

We model non-response as a function of age, with higher likelihood of not 
responding to the survey for older customers:

```{r}
no.response <- as.logical(rbinom(ncust, size = 1, prob = cust.df$age/100))
sat.service[no.response] <- NA
sat.selection[no.response] <- NA
summary(cbind(sat.service, sat.selection))
```

```{r}
cust.df$sat.service <- sat.service
cust.df$sat.selection <- sat.selection
summary(cust.df)
rm(ncust, sat.overall, sat.service, sat.selection, no.response)
```

# Exploring Associations Between Variables with Scatterplots

```{r}
str(cust.df)
```

Relationship between each customer's age and credit score:

```{r}
plot(cust.df$age, cust.df$credit.score,
     col = "blue",
     xlim = c(15, 55), ylim = c(500, 900),
     main = "Active Customers as of June 2014",
     xlab = "Customer Age (years)", ylab = "Customer Credit Score")
abline(h = mean(cust.df$credit.score), col = "dark blue", lty = "dotted")
abline(v = mean(cust.df$age), col = "dark blue", lty = "dotted")
```

In our data, do customers who buy more online buy less in stores?

```{r}
plot(cust.df$store.spend, cust.df$online.spend,
     main = "Customers as of June 2014",
     xlab = "Prior 12 months in-store sales ($)",
     ylab = "Prior 12 months online sales ($)",
     cex = 0.7)
```

There are a large number of customers who didn't buy anything on one of 
the two channels (the points along the axes), along with a smaller number 
of customers who purchase fairly large amounts on one of the channels.

```{r}
hist(cust.df$store.spend,
     breaks = (0:ceiling(max(cust.df$store.spend) / 10)) * 10,
     main = "Customers as of June 2014",
     xlab = "Prior 12 months in-store sales ($)",
     ylab = "Count of customers")
```

## Color-Coding Points on a Scatterplot

Another question is whether the propensity to buy online versus in store is 
related to our email efforts:

```{r}
my.col <- c("black", "green3")
my.pch <- c(1, 19)
```

```{r}
head(cust.df$email)
as.numeric(head(cust.df$email))
my.col[head(cust.df$email)]
```

Both online and in-store sales are skewed:

```{r}
plot(cust.df$store.spend, cust.df$online.spend,
     cex = 0.7,
     col = my.col[cust.df$email], pch = my.pch[cust.df$email],
     main = "Customers as of June 2014",
     xlab = "Prior 12 months in-store sales ($)",
     ylab = "Prior 12 months online sales ($)")
legend(x = "topright", legend = paste("email on file:", levels(cust.df$email)),
       col = my.col, pch = my.pch)
```

We use log scale for both axes (the distance from 1 to 10 is the same 
as 10 to 100):

```{r}
plot(cust.df$store.spend + 1, cust.df$online.spend + 1, # log(0) is not defined
     cex = 0.7,
     log = "xy",
     col = my.col[cust.df$email], pch = my.pch[cust.df$email],
     main = "Customers as of June 2014",
     xlab = "Prior 12 months in-store sales ($)",
     ylab = "Prior 12 months online sales ($)")
legend(x = "topright", legend = paste("email on file:", levels(cust.df$email)),
       col = my.col, pch = my.pch)
```

It now appears that there is little or no association between online and 
in-store sales; the scatterplot shows no pattern. Thus, there is no evidence 
here to suggest that online sales have cannibalized in-store sales.

There may be a negative relationship between customers' distances to the 
nearest store and *in-store* spending, however we don't see an obvious 
relationship between distance and *online* spending:

```{r}
par(mfrow = c(2, 2))
with(cust.df, {
        plot(distance.to.store, store.spend, main = "store")
        plot(distance.to.store, online.spend, main = "online")
        plot(distance.to.store, store.spend + 1, 
             main = "store, log", log = "xy")
        plot(distance.to.store, online.spend + 1, 
             main = "online, log", log = "xy")
})
par(mfrow = c(1, 1))
```

# Scatterplot Matrices

```{r}
pairs(formula = ~ age + credit.score + email + distance.to.store + 
              online.visits + online.trans + online.spend + 
              store.trans + store.spend,
      data = cust.df)
```

```{r}
library(car)
scatterplotMatrix(formula = ~ age + credit.score + email + 
                          distance.to.store + online.visits + 
                          online.trans + online.spend + 
                          store.trans + store.spend,
                  data = cust.df, diagonal = "histogram")
```

```{r}
library(gpairs)
gpairs(cust.df[ , c(2:10)])
```

# Correlation Coefficients

```{r}
cov(cust.df$age, cust.df$credit.score)
```

But *covariance* will be different if the variables are measured in cents 
versus dollars or in inches versus centimeters...

It is helpful to scale the covariance by the standard deviation for each 
variable, with the *Pearson product-moment correlation coefficient*:

```{r}
cor(cust.df$age, cust.df$credit.score)
```

Pearson's *r* is +1 in the case of a perfect positive linear association 
between the two variables, and -1 for perfect negative association. If there 
is little or no linear association, *r* will be near 0.

## When *normally distributed*

In Social Sciences such as marketing, we often use *Cohen's Rules of Thumb*. 
Cohen proposed that for correlations between variables describing people, 
r = 0.1 should be considered a *small* or *weak* association, r = 0.3 
might be considered to be *medium* in strength, and r = 0.5 or higher could 
be considered to be *large* or *strong*.

[(Statistical vs. PracticalSignificance)](http://gradnyc.com/wp-content/uploads/2012/08/GNYC_Academy_Workshop-4_Statistical-vs-Practical-Significance.pdf)

## Correlation Tests

Is it statistically significant?

```{r}
cor.test(cust.df$age, cust.df$credit.score)
```

Because the confidence interval for *r* does not include 0, the association 
is statistically significant.

## Correlation Matrices

```{r}
cor(cust.df[ , c(2, 3, 5:12)])
```

```{r}
library(corrplot)
library(gplots)
corrplot.mixed(corr = cor(cust.df[ , c(2, 3, 5:12)], use = "complete.obs"),
               upper = "ellipse", tl.pos = "lt",
               col = colorpanel(50, "red", "gray50", "blue4"))
```

## Box-Cox Transformations

```{r}
library(car)
powerTransform(cust.df$distance.to.store)
```

```{r}
lambda <- coef(powerTransform(cust.df$distance.to.store))
par(mfrow = c(1, 2))
hist(cust.df$distance.to.store,
     xlab = "Distance to Nearest Store", ylab = "Count of Customers",
     main = "Original Distribution")
hist(bcPower(cust.df$distance.to.store, lambda),
     xlab = "Box-Cox Transform of Distance", ylab = "Count of Customers",
     main = "Transformed Distribution")
par(mfrow = c(1, 1))
```

# Exploring Associations in Survey Responses

One way to make a plot of ordinal values more informative is to *jitter* 
each variable:

```{r}
plot(jitter(cust.df$sat.service), jitter(cust.df$sat.selection),
     xlab = "Customer Satisfaction with Service",
     ylab = "Customer Satisfaction with Selection",
     main = "Customers as of June 2014")
```
